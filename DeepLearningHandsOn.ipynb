{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DeepLearningHandsOn.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Stephen-LiuHan/Keras/blob/master/DeepLearningHandsOn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8r53NhJkUidN",
        "colab_type": "code",
        "outputId": "c7627f5f-7f0e-420c-cc8f-d482e37c15f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install h5py\n",
        "!pip install tensorflow\n",
        "!pip install keras"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from h5py) (1.11.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.6/dist-packages (from h5py) (1.14.6)\n",
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.12.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.6)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.6.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.5)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.32.2)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.13.0,>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: absl-py>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.6.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow) (40.5.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.10 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (0.14.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.13.0,>=1.12.0->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.6/dist-packages (2.2.4)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.5)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras) (1.14.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras) (1.0.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras) (2.8.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras) (1.1.0)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras) (1.11.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras) (3.13)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "-VDv-zLoWc_F",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "git clone https://github.com/Stephen-LiuHan/Keras.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sc-BbzhrWt5S",
        "colab_type": "code",
        "outputId": "4815ccc7-9ab7-43ec-a57f-e035e8d1a539",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "H-2jPhTTW1eZ",
        "colab_type": "code",
        "outputId": "f2ceb571-6469-429f-dc34-c1d4a72601fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "model =Sequential()\n",
        "\n",
        "model.add(Dense(1,input_dim=8,kernel_initializer='random_uniform'))\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 9\n",
            "Trainable params: 9\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "J-MjVdPGXmO0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "from time import gmtime, strftime\n",
        "from keras.callbacks import TensorBoard\n",
        "\n",
        "def make_tensorboard(set_dir_name=\"\"):\n",
        "  tictoc = strftime(\"%a_%d_%b_%Y_%H_%M_%S\",gmtime())\n",
        "  directory_name = tictoc\n",
        "  log_dir = set_dir_name+'_'+directory_name\n",
        "  os.mkdir(log_dir)\n",
        "  tensorboard = TensorBoard(log_dir=log_dir)\n",
        "  return tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q-bDThuUdQlN",
        "colab_type": "code",
        "outputId": "add689be-bb12-411e-c274-77a736291ac8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2006
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense,Activation\n",
        "from keras.optimizers import SGD\n",
        "from keras.utils import np_utils\n",
        "\n",
        "NB_EPOCH =50\n",
        "BATCH_SIZE = 128\n",
        "VERBOSE = 1\n",
        "NB_CLASSES =10\n",
        "OPTIMIZER = SGD()\n",
        "N_HiDEN = 128\n",
        "VALIDATION_SPLIT = 0.2\n",
        "\n",
        "(X_train,y_train),(X_test,y_test)=mnist.load_data()\n",
        "\n",
        "RESHAPED=784\n",
        "\n",
        "X_train=X_train.reshape(60000,RESHAPED)\n",
        "X_test= X_test.reshape(10000,RESHAPED)\n",
        "X_train=X_train.astype('float32')\n",
        "X_test =X_test.astype('float32')\n",
        "\n",
        "X_train/= 255\n",
        "X_test /= 255\n",
        "\n",
        "print(X_train.shape[0],'train samples')\n",
        "print(X_test.shape[0],'test samples')\n",
        "\n",
        "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
        "Y_test = np_utils.to_categorical(y_test,NB_CLASSES)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()\n",
        "\n",
        "callbacks = [make_tensorboard(set_dir_name='keras_MNIST_V1')]\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',optimizer=OPTIMIZER,\n",
        "             metrics=['accuracy'])\n",
        "\n",
        "model.fit(X_train,Y_train,batch_size=BATCH_SIZE,epochs=NB_EPOCH,\n",
        "         callbacks=callbacks,verbose=VERBOSE,validation_split=VALIDATION_SPLIT)\n",
        "score = model.evaluate(X_test,Y_test,verbose=VERBOSE)\n",
        "print(\"¥nTest score:\",score[0])\n",
        "print(\"Test accuracy:\",score[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "60000 train samples\n",
            "10000 test samples\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 10)                0         \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 48000 samples, validate on 12000 samples\n",
            "Epoch 1/50\n",
            "48000/48000 [==============================] - 1s 25us/step - loss: 1.3625 - acc: 0.6842 - val_loss: 0.8824 - val_acc: 0.8356\n",
            "Epoch 2/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.7852 - acc: 0.8298 - val_loss: 0.6520 - val_acc: 0.8603\n",
            "Epoch 3/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.6394 - acc: 0.8509 - val_loss: 0.5589 - val_acc: 0.8703\n",
            "Epoch 4/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.5684 - acc: 0.8612 - val_loss: 0.5070 - val_acc: 0.8776\n",
            "Epoch 5/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.5252 - acc: 0.8682 - val_loss: 0.4733 - val_acc: 0.8816\n",
            "Epoch 6/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.4954 - acc: 0.8732 - val_loss: 0.4494 - val_acc: 0.8864\n",
            "Epoch 7/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.4733 - acc: 0.8776 - val_loss: 0.4317 - val_acc: 0.8890\n",
            "Epoch 8/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.4561 - acc: 0.8810 - val_loss: 0.4176 - val_acc: 0.8912\n",
            "Epoch 9/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.4423 - acc: 0.8831 - val_loss: 0.4060 - val_acc: 0.8940\n",
            "Epoch 10/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.4308 - acc: 0.8857 - val_loss: 0.3967 - val_acc: 0.8957\n",
            "Epoch 11/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.4211 - acc: 0.8872 - val_loss: 0.3885 - val_acc: 0.8977\n",
            "Epoch 12/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.4128 - acc: 0.8892 - val_loss: 0.3816 - val_acc: 0.8993\n",
            "Epoch 13/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.4055 - acc: 0.8907 - val_loss: 0.3756 - val_acc: 0.9005\n",
            "Epoch 14/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3990 - acc: 0.8919 - val_loss: 0.3703 - val_acc: 0.9009\n",
            "Epoch 15/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3933 - acc: 0.8927 - val_loss: 0.3655 - val_acc: 0.9016\n",
            "Epoch 16/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3881 - acc: 0.8940 - val_loss: 0.3612 - val_acc: 0.9021\n",
            "Epoch 17/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3835 - acc: 0.8951 - val_loss: 0.3574 - val_acc: 0.9029\n",
            "Epoch 18/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3792 - acc: 0.8957 - val_loss: 0.3539 - val_acc: 0.9043\n",
            "Epoch 19/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3754 - acc: 0.8961 - val_loss: 0.3506 - val_acc: 0.9056\n",
            "Epoch 20/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3718 - acc: 0.8976 - val_loss: 0.3476 - val_acc: 0.9055\n",
            "Epoch 21/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3684 - acc: 0.8983 - val_loss: 0.3449 - val_acc: 0.9069\n",
            "Epoch 22/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3653 - acc: 0.8988 - val_loss: 0.3424 - val_acc: 0.9072\n",
            "Epoch 23/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3625 - acc: 0.8992 - val_loss: 0.3399 - val_acc: 0.9079\n",
            "Epoch 24/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3597 - acc: 0.9000 - val_loss: 0.3379 - val_acc: 0.9080\n",
            "Epoch 25/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3572 - acc: 0.9005 - val_loss: 0.3358 - val_acc: 0.9091\n",
            "Epoch 26/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3549 - acc: 0.9011 - val_loss: 0.3340 - val_acc: 0.9082\n",
            "Epoch 27/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3527 - acc: 0.9018 - val_loss: 0.3319 - val_acc: 0.9097\n",
            "Epoch 28/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3505 - acc: 0.9028 - val_loss: 0.3304 - val_acc: 0.9096\n",
            "Epoch 29/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3485 - acc: 0.9031 - val_loss: 0.3286 - val_acc: 0.9101\n",
            "Epoch 30/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3466 - acc: 0.9033 - val_loss: 0.3272 - val_acc: 0.9107\n",
            "Epoch 31/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3448 - acc: 0.9040 - val_loss: 0.3257 - val_acc: 0.9112\n",
            "Epoch 32/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3431 - acc: 0.9045 - val_loss: 0.3243 - val_acc: 0.9115\n",
            "Epoch 33/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3414 - acc: 0.9047 - val_loss: 0.3229 - val_acc: 0.9112\n",
            "Epoch 34/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3399 - acc: 0.9050 - val_loss: 0.3216 - val_acc: 0.9120\n",
            "Epoch 35/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3383 - acc: 0.9055 - val_loss: 0.3204 - val_acc: 0.9116\n",
            "Epoch 36/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3369 - acc: 0.9058 - val_loss: 0.3192 - val_acc: 0.9123\n",
            "Epoch 37/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3355 - acc: 0.9063 - val_loss: 0.3181 - val_acc: 0.9128\n",
            "Epoch 38/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3342 - acc: 0.9065 - val_loss: 0.3171 - val_acc: 0.9127\n",
            "Epoch 39/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3329 - acc: 0.9066 - val_loss: 0.3161 - val_acc: 0.9135\n",
            "Epoch 40/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3316 - acc: 0.9074 - val_loss: 0.3151 - val_acc: 0.9133\n",
            "Epoch 41/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3304 - acc: 0.9078 - val_loss: 0.3141 - val_acc: 0.9138\n",
            "Epoch 42/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3293 - acc: 0.9081 - val_loss: 0.3134 - val_acc: 0.9140\n",
            "Epoch 43/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3282 - acc: 0.9087 - val_loss: 0.3124 - val_acc: 0.9138\n",
            "Epoch 44/50\n",
            "48000/48000 [==============================] - 1s 18us/step - loss: 0.3271 - acc: 0.9086 - val_loss: 0.3116 - val_acc: 0.9142\n",
            "Epoch 45/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3261 - acc: 0.9093 - val_loss: 0.3108 - val_acc: 0.9143\n",
            "Epoch 46/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3251 - acc: 0.9095 - val_loss: 0.3100 - val_acc: 0.9147\n",
            "Epoch 47/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3241 - acc: 0.9095 - val_loss: 0.3092 - val_acc: 0.9148\n",
            "Epoch 48/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3232 - acc: 0.9100 - val_loss: 0.3084 - val_acc: 0.9153\n",
            "Epoch 49/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3223 - acc: 0.9102 - val_loss: 0.3077 - val_acc: 0.9155\n",
            "Epoch 50/50\n",
            "48000/48000 [==============================] - 1s 19us/step - loss: 0.3214 - acc: 0.9105 - val_loss: 0.3071 - val_acc: 0.9153\n",
            "10000/10000 [==============================] - 0s 16us/step\n",
            "¥nTest score: 0.3076238003969193\n",
            "Test accuracy: 0.9145\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Uwz5gjcEj88U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "0167b0bb-31c9-4f92-9281-2b782fa6065e"
      },
      "cell_type": "code",
      "source": [
        "%whos"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Variable           Type                          Data/Info\n",
            "----------------------------------------------------------\n",
            "Activation         type                          <class 'keras.layers.core.Activation'>\n",
            "BATCH_SIZE         int                           128\n",
            "Dense              type                          <class 'keras.layers.core.Dense'>\n",
            "NB_CLASSES         int                           10\n",
            "NB_EPOCH           int                           50\n",
            "N_HiDEN            int                           128\n",
            "OPTIMIZER          SGD                           <keras.optimizers.SGD object at 0x7f6ac14e9908>\n",
            "RESHAPED           int                           784\n",
            "SGD                type                          <class 'keras.optimizers.SGD'>\n",
            "Sequential         type                          <class 'keras.engine.sequential.Sequential'>\n",
            "TensorBoard        type                          <class 'keras.callbacks.TensorBoard'>\n",
            "VALIDATION_SPLIT   float                         0.2\n",
            "VERBOSE            int                           1\n",
            "X_test             ndarray                       10000x784: 7840000 elems, type `float32`, 31360000 bytes (29.9072265625 Mb)\n",
            "X_train            ndarray                       60000x784: 47040000 elems, type `float32`, 188160000 bytes (179.443359375 Mb)\n",
            "Y_test             ndarray                       10000x10: 100000 elems, type `float32`, 400000 bytes (390.625 kb)\n",
            "Y_train            ndarray                       60000x10: 600000 elems, type `float32`, 2400000 bytes (2.288818359375 Mb)\n",
            "callbacks          list                          n=1\n",
            "gmtime             builtin_function_or_method    <built-in function gmtime>\n",
            "make_tensorboard   function                      <function make_tensorboard at 0x7f6ac15bf268>\n",
            "mnist              module                        <module 'keras.datasets.m<...>keras/datasets/mnist.py'>\n",
            "model              Sequential                    <keras.engine.sequential.<...>object at 0x7f6ac14e9c88>\n",
            "np                 module                        <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
            "np_utils           module                        <module 'keras.utils.np_u<...>keras/utils/np_utils.py'>\n",
            "os                 module                        <module 'os' from '/usr/lib/python3.6/os.py'>\n",
            "print_function     _Feature                      _Feature((2, 6, 0, 'alpha<...>0, 0, 'alpha', 0), 65536)\n",
            "score              list                          n=2\n",
            "strftime           builtin_function_or_method    <built-in function strftime>\n",
            "y_test             ndarray                       10000: 10000 elems, type `uint8`, 10000 bytes\n",
            "y_train            ndarray                       60000: 60000 elems, type `uint8`, 60000 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x7gCJjqsWMQG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "outputId": "0b396ba7-41b6-481c-ab0c-f762840da72c"
      },
      "cell_type": "code",
      "source": [
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(X_train[0,:].reshape(28,28))\n",
        "plt.show()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAUsAAAFKCAYAAACU6307AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAEyJJREFUeJzt3X1MlfX/x/HXiRPCGTgEOWxu3c2p\nsdQ5GxaaJjezdGt5UxkMXcstrUneZI5R0o2bKGFLpE2htCZrnUW2anOD7GYzhzhZo0ErzC1HZohF\n5g0anPj98dv3TBTlzeEcrgM9H391PufN57yvrnrtc53rXNfl6unp6REA4KZucboBABgOCEsAMCAs\nAcCAsAQAA8ISAAwISwAwICwBwICwBAADd7B/uGXLFjU2NsrlcqmwsFBTp04NZV8AEFGCCsujR4/q\n5MmT8vl8OnHihAoLC+Xz+ULdGwBEjKAOw+vq6pSdnS1JGj9+vM6dO6cLFy6EtDEAiCRBheXZs2c1\nZsyYwOvExES1t7eHrCkAiDQhOcHDvTgAjHRBhaXX69XZs2cDr8+cOaPk5OSQNQUAkSaosJw1a5Zq\namokSc3NzfJ6vYqLiwtpYwAQSYI6Gz59+nTdc889evLJJ+VyufTKK6+Eui8AiCgubv4LAP3jCh4A\nMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCA\nsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8IS\nAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAw\nICwBwMDtdAMY+f79919z7ZUrV8LYSW+xsbHq7OzsNfb++++b/vbixYvmz/nhhx/MtW+99Za5trCw\n8LqxnTt3Kj8/v9dYeXm5ec7Y2Fhz7fbt2011zz77rHnOSMbKEgAMglpZ1tfXa82aNZowYYIkaeLE\nidq0aVNIGwOASBL0YfiMGTNUVlYWyl4AIGJxGA4ABkGH5c8//6xVq1YpJydHhw8fDmVPABBxXD09\nPT0D/aO2tjY1NDRo/vz5am1t1fLly1VbW6vo6Ohw9AgAjgvqO8uUlBQtWLBAknT77bdr7Nixamtr\n02233RbS5jAy8NMhfjo0EgR1GP7ZZ5/p3XfflSS1t7frjz/+UEpKSkgbA4BIEtTKMjMzUxs2bNCX\nX36prq4uvfrqqxyCAxjRggrLuLg47dq1K9S9AEDECuoED5x37tw5c63f7zfXNjY29jmekZGhr7/+\nOvC6trbWPOdff/1lrq2oqDDXDpbf71dUVFTYP+fOO+8012ZlZZlr//dV2NX62qb4+HjznLNnzzbX\nlpaWmuomTZpknjOS8TtLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwIDL\nHSPMr7/+aqqbNm2aec6Ojo5g2wkYqksDh9JgtumWW+zrjC+++MJcO5BbpPXlvvvuU319fa8xr9dr\n/vu4uDhzbXJysrl2JGBlCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABkE93RHh\nk5SUZKobyHPaQ3EFT6SZN2+eufZm/05zcnJ6vd6/f79pzlGjRpk/f+7cuebaULjvvvuG9PP+K1hZ\nAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAZc7hhhrA+seu+998xzVldX\nm2vT09Nv+N7HH38c+OclS5aY5xyIBx54wFT36aefmueMjo6+4XtVVVW9Xv/++++mOXfs2GH+fIwM\nrCwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA1dPT0+P000gvK5cuWKu\nvdGlgS6XS1f/p1JYWGies6SkxFz79ddfm+rmzJljnhMIBdPKsqWlRdnZ2YHraE+fPq1ly5YpNzdX\na9as0T///BPWJgHAaf2G5aVLl7R58+ZeN1goKytTbm6uPvjgA91xxx0DulEDAAxH/YZldHS0Kisr\n5fV6A2P19fXKysqSJGVkZKiuri58HQJABOj3Fm1ut1tud++yzs7OwHdbSUlJam9vD093ABAhBn0/\nS84PRb5Ro0aFZB6XyxX45+LiYvPfDaQWiFRBhaXH49Hly5cVExOjtra2XofoiDycDQcGL6jfWc6c\nOVM1NTWSpNraWs2ePTukTQFApOl3ZdnU1KRt27bp1KlTcrvdqqmpUWlpqQoKCuTz+TRu3DgtXLhw\nKHoFAMf0G5aTJ0/Wvn37rhvfu3dvWBoCgEjEA8v+A8JxgmfMmDEhmfNaZWVlprqBfPVzdd9AsLg2\nHAAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADDggWUIykCeu5Sbm2uu/eST\nT0x1jY2N5jknT55srgVuhJUlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYA\nYMDljgi7P//801w7fvx4U11iYqJ5zhs913779u164YUXeo3NmjXLNOeiRYvMn8/TJUcGVpYAYEBY\nAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGDAFTyIKEePHjXVPfzww+Y5z5071+e43+9X\nVFSUeZ6r7dmzx1y7ZMkSc21cXFww7WAIsLIEAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAwISwAwICwB\nwICwBAADwhIADNxONwBcbcaMGaa65uZm85zr1q274XuPP/54r9cfffSRac6nn37a/PknTpww1774\n4ovm2vj4eHMtBo+VJQAYmMKypaVF2dnZqqqqkiQVFBTokUce0bJly7Rs2TJ988034ewRABzX72H4\npUuXtHnzZqWnp/caX79+vTIyMsLWGABEkn5XltHR0aqsrJTX6x2KfgAgIpnvZ7lz506NGTNGeXl5\nKigoUHt7u7q6upSUlKRNmzYpMTEx3L0CgGOCOhv+6KOPKiEhQampqaqoqFB5ebmKiopC3RtwQ6dP\nnzbX3uhs+Icffqgnn3yy15j1bPhAvPTSS+ZazoZHrqDOhqenpys1NVWSlJmZqZaWlpA2BQCRJqiw\nzM/PV2trqySpvr5eEyZMCGlTABBp+j0Mb2pq0rZt23Tq1Cm53W7V1NQoLy9Pa9euVWxsrDwej4qL\ni4eiVwBwTL9hOXnyZO3bt++68YceeigsDQFAJOLpjhjxLl++3Od4TEzMde8dOXLENGd2drb58wfy\nv9hjjz1mrvX5fOZaDB6XOwKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgAFhCQAG\nXO4IBGHUqFHm2u7ubnOt222/xez3339/3dikSZP0008/XTeGwWNlCQAGhCUAGBCWAGBAWAKAAWEJ\nAAaEJQAYEJYAYEBYAoABYQkABvbLBYAI8ttvv5lr9+/f3+f46tWrVV5e3musrq7ONOdArsoZiLS0\nNHPtxIkTBzSOwWFlCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABjwwDKE\nXXt7u7n27bffNtXt3bvXPOevv/7a57jf71dUVJR5nmAN5DOeeOIJc21VVVUw7SBIrCwBwICwBAAD\nwhIADAhLADAgLAHAgLAEAAPCEgAMCEsAMCAsAcCAsAQAA57uiF4uXLjQ53hcXFyv9z7//HPznK+/\n/rq5tqWlxVzrpMzMTHPt1q1bzbX33ntvMO1gCJjCsqSkRA0NDeru7tbKlSs1ZcoUbdy4UX6/X8nJ\nyXrjjTcUHR0d7l4BwDH9huWRI0d0/Phx+Xw+dXR0aNGiRUpPT1dubq7mz5+vN998U9XV1crNzR2K\nfgHAEf1+Z5mWlqYdO3ZIkkaPHq3Ozk7V19crKytLkpSRkWF+MD0ADFf9hmVUVJQ8Ho8kqbq6WnPm\nzFFnZ2fgsDspKWlAt+ACgOHIfILn4MGDqq6u1p49ezRv3rzAOLfDHFni4uJM7+Xk5JjnHEjtUPP7\n/U63gGHCFJaHDh3Srl279M477yg+Pl4ej0eXL19WTEyM2tra5PV6w90nhsh/6Wz4YG7+y9nw/55+\nD8PPnz+vkpIS7d69WwkJCZKkmTNnqqamRpJUW1ur2bNnh7dLAHBYvyvLAwcOqKOjQ2vXrg2Mbd26\nVS+//LJ8Pp/GjRunhQsXhrVJAHBav2G5dOlSLV269LrxgTwDBQCGO67gGaYuXrxorm1tbTXX5uXl\n9Tl+7NgxzZ07N/D6u+++M8/ptKtPSPb33muvvWaaMy0tzfz5LpfLXIvIxbXhAGBAWAKAAWEJAAaE\nJQAYEJYAYEBYAoABYQkABoQlABgQlgBgQFgCgIGrhxtShl1nZ6e59uobltzMt99+a57zxx9/NNfe\nyGBuZzYQCxYsMNUVFRWZ55w2bVqf47feequ6urquGwP6wsoSAAwISwAwICwBwICwBAADwhIADAhL\nADAgLAHAgLAEAAPCEgAMCEsAMODpjtf45ZdfTHVbtmzpc7yiokLPPPNMr7GDBw+aP//kyZPmWid5\nPB5z7ebNm821zz33nKkuOjraPOfNcHkjrFhZAoABYQkABoQlABgQlgBgQFgCgAFhCQAGhCUAGBCW\nAGBAWAKAAQ8su8b27dtNdRs3buxzfKge7DV9+nRzbU5OjrnW7e77oq7nn39eZWVlgdfXXqV0MzEx\nMeZaIFKxsgQAA8ISAAwISwAwICwBwICwBAADwhIADAhLADAgLAHAgLAEAAPCEgAMuNwRAAxMT3cs\nKSlRQ0ODuru7tXLlSn311Vdqbm5WQkKCJGnFihWaO3duOPsEAEf1G5ZHjhzR8ePH5fP51NHRoUWL\nFun+++/X+vXrlZGRMRQ9AoDj+g3LtLQ0TZ06VZI0evRodXZ2yu/3h70xAIgkA/rO0ufz6dixY4qK\nilJ7e7u6urqUlJSkTZs2KTExMZx9AoCjzGF58OBB7d69W3v27FFTU5MSEhKUmpqqiooK/f777yoq\nKgp3rwDgGNNPhw4dOqRdu3apsrJS8fHxSk9PV2pqqiQpMzNTLS0tYW0SAJzWb1ieP39eJSUl2r17\nd+Dsd35+vlpbWyVJ9fX1mjBhQni7BACH9XuC58CBA+ro6NDatWsDY4sXL9batWsVGxsrj8ej4uLi\nsDYJAE7jR+kAYMDljgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkA\nBoQlABgQlgBgQFgCgAFhCQAGhCUAGBCWAGBAWAKAAWEJAAaEJQAYEJYAYEBYAoABYQkABoQlABgQ\nlgBgQFgCgAFhCQAGhCUAGBCWAGDgduJDt2zZosbGRrlcLhUWFmrq1KlOtBFS9fX1WrNmjSZMmCBJ\nmjhxojZt2uRwV8FraWnRc889p6eeekp5eXk6ffq0Nm7cKL/fr+TkZL3xxhuKjo52us0BuXabCgoK\n1NzcrISEBEnSihUrNHfuXGebHKCSkhI1NDSou7tbK1eu1JQpU4b9fpKu366vvvrK8X015GF59OhR\nnTx5Uj6fTydOnFBhYaF8Pt9QtxEWM2bMUFlZmdNtDNqlS5e0efNmpaenB8bKysqUm5ur+fPn6803\n31R1dbVyc3Md7HJg+tomSVq/fr0yMjIc6mpwjhw5ouPHj8vn86mjo0OLFi1Senr6sN5PUt/bdf/9\n9zu+r4b8MLyurk7Z2dmSpPHjx+vcuXO6cOHCULeBm4iOjlZlZaW8Xm9grL6+XllZWZKkjIwM1dXV\nOdVeUPrapuEuLS1NO3bskCSNHj1anZ2dw34/SX1vl9/vd7grB8Ly7NmzGjNmTOB1YmKi2tvbh7qN\nsPj555+1atUq5eTk6PDhw063EzS3262YmJheY52dnYHDuaSkpGG3z/raJkmqqqrS8uXLtW7dOv35\n558OdBa8qKgoeTweSVJ1dbXmzJkz7PeT1Pd2RUVFOb6vHPnO8mo9PT1OtxASd955p1avXq358+er\ntbVVy5cvV21t7bD8vqg/I2WfPfroo0pISFBqaqoqKipUXl6uoqIip9sasIMHD6q6ulp79uzRvHnz\nAuPDfT9dvV1NTU2O76shX1l6vV6dPXs28PrMmTNKTk4e6jZCLiUlRQsWLJDL5dLtt9+usWPHqq2t\nzem2Qsbj8ejy5cuSpLa2thFxOJuenq7U1FRJUmZmplpaWhzuaOAOHTqkXbt2qbKyUvHx8SNmP127\nXZGwr4Y8LGfNmqWamhpJUnNzs7xer+Li4oa6jZD77LPP9O6770qS2tvb9ccffyglJcXhrkJn5syZ\ngf1WW1ur2bNnO9zR4OXn56u1tVXS/38n+79fMgwX58+fV0lJiXbv3h04SzwS9lNf2xUJ+8rV48Ba\nvbS0VMeOHZPL5dIrr7yiu+++e6hbCLkLFy5ow4YN+vvvv9XV1aXVq1frwQcfdLqtoDQ1NWnbtm06\ndeqU3G63UlJSVFpaqoKCAl25ckXjxo1TcXGxbr31VqdbNetrm/Ly8lRRUaHY2Fh5PB4VFxcrKSnJ\n6VbNfD6fdu7cqbvuuiswtnXrVr388svDdj9JfW/X4sWLVVVV5ei+ciQsAWC44QoeADAgLAHAgLAE\nAAPCEgAMCEsAMCAsAcCAsAQAA8ISAAz+D4GsMlewG9H3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<matplotlib.figure.Figure at 0x7f6ac15bc748>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "NYN9NmuOXq0i",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}